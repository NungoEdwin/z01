{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827e2eb0-01fc-4dbf-b3c9-dbe6cb695558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "TRAIN: [2 3 4 5 6 7 8 9] TEST: [0 1]\n",
      "\n",
      "Fold: 2\n",
      "TRAIN: [0 1 4 5 6 7 8 9] TEST: [2 3]\n",
      "\n",
      "Fold: 3\n",
      "TRAIN: [0 1 2 3 6 7 8 9] TEST: [4 5]\n",
      "\n",
      "Fold: 4\n",
      "TRAIN: [0 1 2 3 4 5 8 9] TEST: [6 7]\n",
      "\n",
      "Fold: 5\n",
      "TRAIN: [0 1 2 3 4 5 6 7] TEST: [8 9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise1 \n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = np.array(np.arange(1, 21).reshape(10, -1))\n",
    "y = np.array(np.arange(1, 11))\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    print(f\"Fold: {fold}\")\n",
    "    print(f\"TRAIN: {train_index} TEST: {test_index}\\n\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7e2c64-eecd-4d6e-9792-33a14e0cbf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on validation sets:\n",
      "[0.62433594 0.61648956 0.62486602 0.59891024 0.59284295 0.61307055\n",
      " 0.54630341 0.60742976 0.60014575 0.59574508]\n",
      "\n",
      "Mean of scores on validation sets:\n",
      "0.6020139252674299\n",
      "\n",
      "Standard deviation of scores on validation sets:\n",
      "0.02149838227734666\n"
     ]
    }
   ],
   "source": [
    "#Exercise2\n",
    "# imports\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "\n",
    "# split data train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=43)\n",
    "\n",
    "# pipeline\n",
    "pipeline = [('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lr', LinearRegression())]\n",
    "pipe = Pipeline(pipeline)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Cross-validate with 10 folds\n",
    "cv_results = cross_validate(pipe, X_train, y_train, cv=10, scoring='r2')\n",
    "\n",
    "scores = cv_results['test_score']\n",
    "print(\"Scores on validation sets:\")\n",
    "print(scores)\n",
    "\n",
    "mean_score = scores.mean()\n",
    "print(\"\\nMean of scores on validation sets:\")\n",
    "print(mean_score)\n",
    "\n",
    "std_score = scores.std()\n",
    "print(\"\\nStandard deviation of scores on validation sets:\")\n",
    "print(std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa78876-46f9-4623-96b0-3fb3a37e5a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 3\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "# split data train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=43)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [1, 5, 10, 15, 20],  # Tree depth: deeper trees can overfit\n",
    "    'n_estimators': [10, 50, 100]     # Number of trees: more trees reduce variance but increase time\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=43)  \n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',  # Negative MSE (since GridSearch maximizes)\n",
    "    n_jobs=-1  # Use all CPUs\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be7d68-2413-4203-acc8-bdf8cbadd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"Best parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\nBest score on validation sets (neg MSE):\")\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "print(\"\\nCV results:\")\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdb70f-081d-437b-ac54-29d83de9c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = best_estimator.score(X_test, y_test)\n",
    "print(\"\\nScore on test set (RÂ²):\")\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb726f8-f68f-4a20-a277-b9de74ce4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise4\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "\n",
    "X, y = make_classification(n_samples=100000,\n",
    "                        n_features=30,\n",
    "                        n_informative=10,\n",
    "                        flip_y=0.2,\n",
    "                        random_state=42)\n",
    "\n",
    "param_range = np.arange(1, 21, 2)  \n",
    "\n",
    "train_scores, valid_scores = validation_curve(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    X, y,\n",
    "    param_name=\"max_depth\",\n",
    "    param_range=param_range,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Calculate means and stds\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "valid_mean = np.mean(valid_scores, axis=1)\n",
    "valid_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(param_range, train_mean, label=\"Training score\", color=\"blue\")\n",
    "plt.plot(param_range, valid_mean, label=\"Validation score\", color=\"orange\")\n",
    "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"blue\")\n",
    "plt.fill_between(param_range, valid_mean - valid_std, valid_mean + valid_std, alpha=0.1, color=\"orange\")\n",
    "plt.title(\"Validation curve : max_depth\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Score : ROC AUC\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, validation_scores_mean - validation_scores_std,\n",
    "                     validation_scores_mean + validation_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, validation_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curve(RandomForestClassifier(max_depth=12, random_state=42), \n",
    "                    \"Learning Curve (Random Forest)\", X, y, cv=10, n_jobs=-1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
